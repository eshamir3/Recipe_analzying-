{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Title Here\n",
    "\n",
    "**Name(s)**: Emma Shamir, Meera Sharma\n",
    "\n",
    "**Website Link**: https://eshamir3.github.io/Recipe_analzying-/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "import scipy\n",
    "import sklearn.linear_model\n",
    "\n",
    "from dsc80_utils import * # Feel free to uncomment and use this.\n",
    "\n",
    "interactions_fp = Path(\"food_data\") /\"RAW_interactions.csv\"\n",
    "interactions_raw = pd.read_csv(interactions_fp)\n",
    "\n",
    "recipes_fp = Path(\"food_data\") / \"RAW_recipes.csv\"\n",
    "recipes_raw = pd.read_csv(recipes_fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to analyze the recipes and ratings dataframe. We will investigate the relationship between number of steps in a recipe and the recipe rating. This is an interesting question because it gives us insight into wether there is a relationship between the number of steps a user must go through in order to make a recipe, and their overall rating of the food. If there is a relationship, it would be interesting to understand what might underlie the differences in ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge datasets \n",
    "\n",
    "recipe_interactions = recipes_raw.merge(interactions_raw, left_on='id', right_on= \"recipe_id\", how = 'left').drop(columns = {'recipe_id'})\n",
    "data_types = pd.DataFrame(recipe_interactions.dtypes)\n",
    "\n",
    "#We replaced ratings of 0 with np.nan, since ratings are made on a 1-5 scale. Therefore, if a rating is 0, it means that the rating is missing,\n",
    "#and should be excluded from the dataset in order to not bias calculations done on the ratings column. \n",
    "recipe_interactions['rating']= recipe_interactions['rating'].replace(0.0, np.nan)\n",
    "\n",
    "#add a column with mean ratings \n",
    "recipe_interactions['avg_rating'] = recipe_interactions.groupby('id')['rating'].transform('mean')\n",
    "\n",
    "#date submitted to datetime\n",
    "recipe_interactions['submitted']= pd.to_datetime(recipe_interactions['submitted'])\n",
    "\n",
    "#date created to datetime\n",
    "recipe_interactions['date']= pd.to_datetime(recipe_interactions['date'])\n",
    "\n",
    "# recipe_interactions = recipe_interactions[recipe_interactions[\"minutes\"] <= 1_440] #cleaning the insane outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minutes</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "name      object\n",
       "id         int64\n",
       "minutes    int64\n",
       "...          ...\n",
       "date      object\n",
       "rating   float64\n",
       "review    object\n",
       "\n",
       "[16 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Univariate Analysis: distribution of ratings\n",
    "\n",
    "frequency = recipe_interactions['rating'].value_counts().reset_index()\n",
    "frequency.columns = ['rating', 'Frequency']\n",
    "\n",
    "fig = px.bar(frequency, x='rating', y='Frequency', \n",
    "             title='Frequency of Rating in Recipe Dataset',\n",
    "             labels={'rating': 'Rating', 'Frequency': 'Count'})\n",
    "\n",
    "#fig.show()\n",
    "\n",
    "#testing exporting it as an HTML file \n",
    "\n",
    "fig.write_html('rating_distributions.html', include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have made changes, now I pray that this shit works!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "#need to do bivariate analyis \n",
    "\n",
    "fig_2 = px.scatter(recipe_interactions, x = \"n_ingredients\", y = \"n_steps\")\n",
    "#fig_2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting rating vs time \n",
    "\n",
    "fig_3 = px.scatter(recipe_interactions, x = \"n_steps\", y = 'minutes')\n",
    "\n",
    "#fig_3.show()\n",
    "\n",
    "#we might want to clean this value because it might be a high leverage point "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Assessment of Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         4.0\n",
       "1         5.0\n",
       "2         5.0\n",
       "         ... \n",
       "234426    1.0\n",
       "234427    5.0\n",
       "234428    NaN\n",
       "Name: rating, Length: 234429, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "#look at missing rating \n",
    "recipe_interactions[\"rating\"]\n",
    "\n",
    "#check whether rating is missing depending on another column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing whether rating is dependent on number of ingredients \n",
    "# ing_test_df = recipe_interactions.copy()\n",
    "# ing_test_df[\"missing_rating\"] = ing_test_df[\"rating\"].isna()\n",
    "# ing_test_df\n",
    "\n",
    "# #use the difference of means as out test stat \n",
    "# #want to know whether average number of minutes when the rating is missing is the same as the average number of minutes when the rating\n",
    "# #is not missing \n",
    "# group_means = ing_test_df.groupby(\"missing_rating\")[\"n_ingredients\"].mean()\n",
    "# obs_stat = np.abs(group_means.loc[True] - group_means.loc[False])\n",
    "# # print(obs_stat)\n",
    "\n",
    "\n",
    "# n_repetitions = 1000 \n",
    "\n",
    "# ing_test_diffs = []\n",
    "\n",
    "# for i in range(n_repetitions): \n",
    "#     ing_test_df[\"shuffled_missing\"] = np.random.permutation(ing_test_df[\"missing_rating\"])\n",
    "#     emp_ing_stat = ing_test_df.groupby(\"shuffled_missing\")[\"n_ingredients\"].mean()\n",
    "#     emp_ing_stat = np.abs(emp_ing_stat.loc[True] - emp_ing_stat.loc[False])\n",
    "#     ing_test_diffs.append(emp_ing_stat)\n",
    "\n",
    "# ing_test_p_val = np.mean(ing_test_diffs >= obs_stat)\n",
    "# ing_test_p_val\n",
    "\n",
    "# # print(ing_test_diffs)\n",
    "\n",
    "# signficance_level = 0.05 \n",
    "\n",
    "# significant = ing_test_p_val < signficance_level\n",
    "\n",
    "# print(f\"p value: {ing_test_p_val}\")\n",
    "# print(f\"significance level: {signficance_level}\")\n",
    "# print(f\"is rating MAR dependent on number of ingredients? {significant}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_test_df = recipe_interactions.copy()\n",
    "# min_test_df[\"missing_rating\"] = min_test_df[\"rating\"].isna()\n",
    "\n",
    "# #use the difference of means as out test stat \n",
    "# #want to know whether average number of minutes when the rating is missing is the same as the average number of minutes when the rating\n",
    "# #is not missing \n",
    "# group_means = min_test_df.groupby(\"missing_rating\")[\"minutes\"].mean()\n",
    "# obs_stat = np.abs(group_means.loc[True] - group_means.loc[False])\n",
    "# obs_stat\n",
    "\n",
    "# min_test_diffs = []\n",
    "\n",
    "# for i in range(n_repetitions): \n",
    "#     min_test_df[\"shuffled_missing\"] = np.random.permutation(min_test_df[\"missing_rating\"])\n",
    "#     emp_min_stat = min_test_df.groupby(\"shuffled_missing\")[\"minutes\"].mean()\n",
    "#     emp_min_stat = np.abs(emp_min_stat.loc[True] - emp_min_stat.loc[False])\n",
    "#     min_test_diffs.append(emp_min_stat)\n",
    "\n",
    "# min_test_p_val = np.mean(min_test_diffs >= obs_stat)\n",
    "\n",
    "# signficance_level = 0.05 \n",
    "\n",
    "# significant = min_test_p_val < signficance_level\n",
    "\n",
    "# print(f\"p value: {min_test_p_val}\")\n",
    "# print(f\"significance level: {signficance_level}\")\n",
    "# print(f\"is rating MAR dependent on number of minutes? {significant}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to find a column that it is not MAR on \n",
    "#try date? \n",
    "\n",
    "# date_test_df = recipe_interactions.copy()\n",
    "# date_test_df[\"missing_rating\"] = \n",
    "\n",
    "#use the difference of means as out test stat \n",
    "#want to know whether average number of minutes when the rating is missing is the same as the average number of minutes when the rating\n",
    "#is not missing \n",
    "# group_means = date_test_df.groupby(\"missing_rating\")[\"date\"].mean()\n",
    "# obs_stat = np.abs(group_means.loc[True] - group_means.loc[False])\n",
    "# obs_stat\n",
    "# print(obs_stat)\n",
    "\n",
    "# date_test_diffs = []\n",
    "\n",
    "# for i in range(n_repetitions): \n",
    "#     date_test_df[\"shuffled_missing\"] = np.random.permutation(date_test_df[\"missing_rating\"])\n",
    "#     emp_date_stat = date_test_df.groupby(\"shuffled_missing\")[\"date\"].mean()\n",
    "#     emp_date_stat = np.abs(emp_date_stat.loc[True] - emp_date_stat.loc[False])\n",
    "#     date_test_diffs.append(emp_date_stat)\n",
    "\n",
    "# # date_test_p_val = np.mean(date_test_diffs >= obs_stat)\n",
    "# date_test_p_val = 0\n",
    "# for diff in date_test_diffs: \n",
    "#     if diff >= obs_stat: \n",
    "#         date_test_p_val.append(1)\n",
    "\n",
    "# date_test_p_val = date_test_p_val / len(date_test_diffs)\n",
    "\n",
    "# signficance_level = 0.05 \n",
    "\n",
    "# significant = date_test_p_val < signficance_level\n",
    "\n",
    "# print(f\"p value: {date_test_p_val}\")\n",
    "# print(f\"significance level: {signficance_level}\")\n",
    "# print(f\"is rating MAR dependent on date? {significant}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(49.82922822486933)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_interactions\n",
    "\n",
    "#null hypothesis: The rating does not effect the number of steps \n",
    "#alternative hypothesis: The rating does have an effect on number of steps \n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "df = recipe_interactions\n",
    "\n",
    "# Assuming your dataset is already loaded into a DataFrame called `df`\n",
    "# Ensure that the 'rating' and 'steps' columns are correctly named in the DataFrame\n",
    "df = df.dropna(subset=['rating', 'n_steps'])  # Drop rows with missing values in 'rating' or 'steps'\n",
    "\n",
    "# Group data by rating and extract the number of steps for each group\n",
    "rating_groups = [df[df['rating'] == rating]['n_steps'] for rating in range(1, 6)]\n",
    "\n",
    "# Perform one-way ANOVA test\n",
    "f_stat, p_value = stats.f_oneway(*rating_groups)\n",
    "\n",
    "f_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_steps'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed tvd: 5.809777965286577\n",
      "p-value for permutation test: 0.327\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "#null hypothesis: the number of steps does not affect the rating of a recipe\n",
    "#alternative hypothesis: the number of steps does affect the rating of a recipe\n",
    "\n",
    "#first, we want to drop the rows where the rating is na (this will not help us for our permutation test)\n",
    "\n",
    "hyp_df = recipe_interactions.copy()\n",
    "hyp_df = hyp_df.dropna(subset= \"rating\")\n",
    "\n",
    "#test statistic: tvd \n",
    "#the absolute deviation between the mean of each group and the total mean, divided bty 2 \n",
    "obs_group_means = hyp_df.groupby(\"n_steps\")[\"rating\"].mean()\n",
    "uniform_dist = [recipe_interactions[\"rating\"].mean()] * len(obs_group_means)\n",
    "obs_tvd =np.sum(\n",
    "    np.abs(\n",
    "    obs_group_means - uniform_dist\n",
    "    )\n",
    ") / 2\n",
    "\n",
    "print(f\"observed tvd: {obs_tvd}\")\n",
    "\n",
    "#making a new column of shuffled number test]\n",
    "test_stats = []\n",
    "\n",
    "for i in range(1000):\n",
    "    hyp_df[\"shuffled_n_steps\"] = np.random.permutation(hyp_df[\"n_steps\"])\n",
    "    test_group_means = hyp_df.groupby(\"shuffled_n_steps\")[\"rating\"].mean()\n",
    "    emp_tvd = np.sum(np.abs(test_group_means - uniform_dist)) / 2\n",
    "    test_stats.append(emp_tvd)\n",
    "\n",
    "p_val = np.mean(test_stats >= obs_tvd)\n",
    "print(f\"p-value for permutation test: {p_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Framing a Prediction Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: need to do all the data cleaning here or up at the beginning just so that the training data and the test data are the same \n",
    "\n",
    "#the only database that we're using is the recipes database --> we don't care about ratings or sentiment \n",
    "\n",
    "cleaned_recipes = recipes_raw.copy()\n",
    "\n",
    "# cleaned_recipes[\"minutes_category\"] = cleaned_recipes[\"minutes\"].apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003023857957842324"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#baseline model features: the number of steps and the number of ingredients\n",
    "\n",
    "X = recipe_interactions[[\"n_steps\", \"n_ingredients\"]]\n",
    "y = recipe_interactions[\"minutes\"]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "model.score(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000314618924943888"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding onto the baseline model \n",
    "#let's add a new column to our dataframe that tells us whether the meal is a dessert or not \n",
    "\n",
    "recipe_interactions['dessert'] = recipe_interactions[\"description\"].fillna(\"\").str.contains(\"dessert\").apply(int)\n",
    "\n",
    "X1 = recipe_interactions[[\"n_steps\", \"n_ingredients\", \"dessert\"]]\n",
    "y = recipe_interactions[\"minutes\"]\n",
    "\n",
    "model_1 = LinearRegression()\n",
    "model_1.fit(X1, y)\n",
    "model_1.score(X1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3174.877849507372"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rounding our predictions to the nearest multiple of 5 to see whether we get better accuracy --> because minutes of cook time is ususally rounded to the nearest multiple of 5 \n",
    "from sklearn.metrics import r2_score\n",
    "predictions_unrounded = model_1.predict(X1)\n",
    "\n",
    "#to round: \n",
    "\n",
    "rounded_predictions = np.round(predictions_unrounded / 5) * 5 \n",
    "\n",
    "#now to calculate the r^2 of this (to get the score)\n",
    "score = r2_score(rounded_predictions, recipe_interactions[\"minutes\"])\n",
    "score\n",
    "\n",
    "# how the heck is score negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7180174390249461"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowkey trying a KNN classifier trying to predict rating \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "test = recipe_interactions.dropna(subset=[\"rating\"])\n",
    "\n",
    "cat_X = test[[\"n_steps\", \"n_ingredients\"]]\n",
    "y = test[\"rating\"]\n",
    "\n",
    "cat_model = KNeighborsClassifier()\n",
    "\n",
    "cat_model.fit(cat_X, y)\n",
    "cat_model.score(cat_X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation in order to find the best hyperparameters to include in our model\n",
    "\n",
    "#do some feature engineering for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6436063797567707"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANOTHER IDEA: make minutes into a categorical column and then try to predict the category that a recipe's time is in\n",
    "\n",
    "#examples of categories: Weekday (less than an hour), Weekend (1-3 hours), Holiday/Special Occasion (3-12 hours), Long Term Recipes (> 12 hours)\n",
    "\n",
    "categorical_mins_model = KNeighborsClassifier(n_neighbors= 6)\n",
    "\n",
    "def categorize_mins(time): \n",
    "    if time < 60: \n",
    "        return \"Weekday\"\n",
    "    elif time < 180: \n",
    "        return \"Weekend\"\n",
    "    elif time < 720: \n",
    "        return \"Holiday/Special Occasion\"\n",
    "    else:\n",
    "        return \"Long Term Recipes\"\n",
    "    \n",
    "y_train = recipe_interactions[\"minutes\"].apply(categorize_mins)\n",
    "\n",
    "X_train = recipe_interactions[[\"n_steps\", \"n_ingredients\"]]\n",
    "\n",
    "categorical_mins_model.fit(X_train, y_train)\n",
    "\n",
    "categorical_mins_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6883701883701884"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(recipe_interactions[[\"n_steps\", \"n_ingredients\"]], recipe_interactions[\"minutes\"].apply(categorize_mins))\n",
    "\n",
    "new_mdl = KNeighborsClassifier()\n",
    "\n",
    "new_mdl.fit(X_train, y_train)\n",
    "\n",
    "new_mdl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>dessert</th>\n",
       "      <th>calories</th>\n",
       "      <th>sodium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 brownies in the world    best ever</td>\n",
       "      <td>333281</td>\n",
       "      <td>40</td>\n",
       "      <td>985201</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>138.4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 in canada chocolate chip cookies</td>\n",
       "      <td>453467</td>\n",
       "      <td>45</td>\n",
       "      <td>1848091</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>595.1</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>412 broccoli casserole</td>\n",
       "      <td>306168</td>\n",
       "      <td>40</td>\n",
       "      <td>50969</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>194.8</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234426</th>\n",
       "      <td>cookies by design   sugar shortbread cookies</td>\n",
       "      <td>298509</td>\n",
       "      <td>20</td>\n",
       "      <td>506822</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>174.9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234427</th>\n",
       "      <td>cookies by design   sugar shortbread cookies</td>\n",
       "      <td>298509</td>\n",
       "      <td>20</td>\n",
       "      <td>506822</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>174.9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234428</th>\n",
       "      <td>cookies by design   sugar shortbread cookies</td>\n",
       "      <td>298509</td>\n",
       "      <td>20</td>\n",
       "      <td>506822</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>174.9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234429 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name      id  minutes  \\\n",
       "0               1 brownies in the world    best ever  333281       40   \n",
       "1                 1 in canada chocolate chip cookies  453467       45   \n",
       "2                             412 broccoli casserole  306168       40   \n",
       "...                                              ...     ...      ...   \n",
       "234426  cookies by design   sugar shortbread cookies  298509       20   \n",
       "234427  cookies by design   sugar shortbread cookies  298509       20   \n",
       "234428  cookies by design   sugar shortbread cookies  298509       20   \n",
       "\n",
       "        contributor_id  ... avg_rating dessert calories  sodium  \n",
       "0               985201  ...        4.0       0    138.4     3.0  \n",
       "1              1848091  ...        5.0       0    595.1    22.0  \n",
       "2                50969  ...        5.0       0    194.8    32.0  \n",
       "...                ...  ...        ...     ...      ...     ...  \n",
       "234426          506822  ...        3.0       0    174.9     4.0  \n",
       "234427          506822  ...        3.0       0    174.9     4.0  \n",
       "234428          506822  ...        3.0       0    174.9     4.0  \n",
       "\n",
       "[234429 rows x 20 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_interactions.columns\n",
    "\n",
    "num_cols = [\"n_steps\", \"n_ingredients\"]\n",
    "\n",
    "# recipe_interactions['nutrition']\n",
    "\n",
    "#to add nutrition values \n",
    "\n",
    "#the values in the nutrition column are strings of lists --> want to transform them into a list \n",
    "\n",
    "def clean_nutrition(stri): \n",
    "    result = stri.strip(\"[]\")\n",
    "    result = result.split(\",\")\n",
    "    result = [float(ele) for ele in result]\n",
    "    return result\n",
    "\n",
    "recipe_interactions['nutrition'].apply(clean_nutrition)\n",
    "\n",
    "\n",
    "def get_calories(lst): \n",
    "    return lst[0]\n",
    "\n",
    "def get_sodium(lst): \n",
    "    return lst[3]\n",
    "\n",
    "nutrition_added_df = recipe_interactions.copy()\n",
    "nutrition_added_df[\"nutrition\"] = nutrition_added_df[\"nutrition\"].apply(clean_nutrition)\n",
    "nutrition_added_df[\"calories\"] = nutrition_added_df[\"nutrition\"].apply(get_calories)\n",
    "nutrition_added_df[\"sodium\"] = nutrition_added_df[\"nutrition\"].apply(get_sodium)\n",
    "\n",
    "nutrition_added_df\n",
    "\n",
    "#hypothesis: things with higher sodium will take longer time to make "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nutrition_added_df[[\"n_ingredients\", \"n_steps\", \"dessert\", \"calories\", \"sodium\"]]\n",
    "y = nutrition_added_df[\"minutes\"].apply(categorize_mins)\n",
    "\n",
    "#making polynomial features \n",
    "#hypothesis: calories^2  or calories ^3 may predict the minutes better than just calories alone \n",
    "\n",
    "#iterative check which polynomial fit is the best for us for minutes. \n",
    "\n",
    "#doing cross validation manually \n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# poly_degrees = range(1, 11)\n",
    "\n",
    "# def eval_polynomial_col(X, y, poly_degrees, col, cv = 5): \n",
    "\n",
    "#     cv_dict = {\"degree\":[], \"accuracy\": []}\n",
    "\n",
    "#     for deg in poly_degrees:\n",
    "\n",
    "#         col_transform = ColumnTransformer(\n",
    "#             transformers = [ (\"poly\", PolynomialFeatures(deg), [col])], remainder = \"passthrough\"\n",
    "#         )\n",
    "\n",
    "#         model = make_pipeline(col_transform, KNeighborsClassifier())\n",
    "\n",
    "#         scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "#         cv_dict[\"degree\"].append(deg)\n",
    "#         cv_dict[\"accuracy\"].append(np.mean(scores))\n",
    "\n",
    "#     return pd.DataFrame(cv_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calorie_cv_results = eval_polynomial_col(X, y, poly_degrees, \"calories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calorie_cv_results[\"accuracy\"].apply(type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "#only need to do cross validation for hyperparameters like n\n",
    "\n",
    "#use grid search CV \n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL MODEL\n",
    "\n",
    "#transformers: \n",
    "#want to standardize calories and sodium \n",
    "#desert is one hot encoded already technically \n",
    "#using n_ingredients and n_steps as is \n",
    "\n",
    "final_col_transform = ColumnTransformer(\n",
    "    transformers= [(\"std_cals\", StandardScaler(), [\"calories\"]),(\"std_sodium\", StandardScaler(), ['sodium']) \n",
    "                   ], remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "final_pipe = Pipeline([\n",
    "    (\"column_transformations\", final_col_transform), (\"model\", KNeighborsClassifier())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8326508326508326"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = X\n",
    "actual_vals = y \n",
    "\n",
    "X_final_train, X_final_split, y_final_train, y_final_split = train_test_split(feature_matrix, actual_vals)\n",
    "\n",
    "final_pipe.fit(X_final_train, y_final_train)\n",
    "\n",
    "final_pipe.score(X_final_split, y_final_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9168543543543544"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search CV in order to find the best hyperparameters for the KNN classifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 10],  # List of neighbors to try\n",
    "    'weights': ['uniform', 'distance'],  # Weight options\n",
    "    'metric': ['euclidean', 'manhattan']}  # Distance metric options \n",
    "grid_search = GridSearchCV(estimator= KNeighborsClassifier(), param_grid=param_grid, \n",
    "                           cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "grid_search.fit(X_final_train, y_final_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_final_model = grid_search.best_estimator_\n",
    "\n",
    "best_final_model.score(X_final_split, y_final_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'distance'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Weekday', 'Weekday', 'Weekday', ..., 'Weekday', 'Weekday',\n",
       "       'Weekend'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_predicts = best_final_model.predict(X_final_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>dessert</th>\n",
       "      <th>calories</th>\n",
       "      <th>sodium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80040</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>698.4</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122306</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>446.1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189102</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230554</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>160.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201570</th>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1124.9</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179597</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>266.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58608 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_ingredients  n_steps  dessert  calories  sodium\n",
       "80040              13       10        0     698.4    30.0\n",
       "122306              8       12        0     446.1     4.0\n",
       "189102              9        3        0     481.0   154.0\n",
       "...               ...      ...      ...       ...     ...\n",
       "230554              3        2        0     160.4     1.0\n",
       "201570             12       45        0    1124.9    20.0\n",
       "179597              6        5        0     266.1    10.0\n",
       "\n",
       "[58608 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "X_final_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rating'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/dsc80/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rating'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m X_final_split\n\u001b[0;32m----> 2\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_rating\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;66;03m#saying that a rating less than 3 is a low rating \u001b[39;00m\n\u001b[1;32m      4\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m final_model_predicts\n",
      "File \u001b[0;32m~/miniforge3/envs/dsc80/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniforge3/envs/dsc80/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rating'"
     ]
    }
   ],
   "source": [
    "result = X_final_split\n",
    "result[\"low_rating\"] = result[\"rating\"].apply(lambda x: x < 3) #saying that a rating less than 3 is a low rating \n",
    "\n",
    "result[\"predicted_label\"] = final_model_predicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
